{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def scan_vocabulary(sents, tokenize, min_count=2):\n",
    "    counter = Counter(w for sent in sents for w in tokenize(sent))\n",
    "    counter = {w:c for w,c in counter.items() if c >= min_count}\n",
    "    idx_to_vocab = [w for w, _ in sorted(counter.items(), key=lambda x:-x[1])]\n",
    "    vocab_to_idx = {vocab:idx for idx, vocab in enumerate(idx_to_vocab)}\n",
    "    return idx_to_vocab, vocab_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def cooccurrence(tokens, vocab_to_idx, window=2, min_cooccurrence=2):\n",
    "    counter = defaultdict(int)\n",
    "    for s, tokens_i in enumerate(tokens):\n",
    "        vocabs = [vocab_to_idx[w] for w in tokens_i if w in vocab_to_idx]\n",
    "        n = len(vocabs)\n",
    "        for i, v in enumerate(vocabs):\n",
    "            if window <= 0:\n",
    "                b, e = 0, n\n",
    "            else:\n",
    "                b = max(0, i - window)\n",
    "                e = min(i + window, n)\n",
    "            for j in range(b, e):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                counter[(v, vocabs[j])] += 1\n",
    "                counter[(vocabs[j], v)] += 1\n",
    "    counter = {k:v for k,v in counter.items() if v >= min_cooccurrence}\n",
    "    n_vocabs = len(vocab_to_idx)\n",
    "    return dict_to_mat(counter, n_vocabs, n_vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def dict_to_mat(d, n_rows, n_cols):\n",
    "    rows, cols, data = [], [], []\n",
    "    for (i, j), v in d.items():\n",
    "        rows.append(i)\n",
    "        cols.append(j)\n",
    "        data.append(v)\n",
    "    return csr_matrix((data, (rows, cols)), shape=(n_rows, n_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_graph(sents, tokenize=None, min_count=2, window=2, min_cooccurrence=2):\n",
    "    idx_to_vocab, vocab_to_idx = scan_vocabulary(sents, tokenize, min_count)\n",
    "    tokens = [tokenize(sent) for sent in sents]\n",
    "    g = cooccurrence(tokens, vocab_to_idx, window, min_cooccurrence, verbose)\n",
    "    return g, idx_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def pagerank(x, df=0.85, max_iter=30):\n",
    "    assert 0 < df < 1\n",
    "\n",
    "    # initialize\n",
    "    A = normalize(x, axis=0, norm='l1')\n",
    "    R = np.ones(A.shape[0]).reshape(-1,1)\n",
    "    bias = (1 - df) * np.ones(A.shape[0]).reshape(-1,1)\n",
    "\n",
    "    # iteration\n",
    "    for _ in range(max_iter):\n",
    "        R = df * (A * R) + bias\n",
    "\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textrank_keyword(sents, tokenize, min_count, window, min_cooccurrence, df=0.85, max_iter=30, topk=30):\n",
    "    g, idx_to_vocab = word_graph(sents, tokenize, min_count, window, min_cooccurrence)\n",
    "    R = pagerank(g, df, max_iter).reshape(-1)\n",
    "    idxs = R.argsort()[-topk:]\n",
    "    keywords = [(idx_to_vocab[idx], R[idx]) for idx in reversed(idxs)]\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
